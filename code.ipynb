{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "CUDA_DEVICES = \"1,2,3,4\"  # Modify as needed\n",
    "OUTPUT_DIR = \"path\"\n",
    "NUM_EPOCHS = 5\n",
    "LR_POLICY = \"stepLR\"\n",
    "OPTION = \"custom\"\n",
    "\n",
    "# Set CUDA devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_DEVICES\n",
    "\n",
    "command = f\"\"\"\n",
    "python -m torch.distributed.launch --nproc_per_node='{len(CUDA_DEVICES.split(\",\"))}' finetune.py \\\n",
    "    --base_model 'meta-llama/Llama-2-7b-hf' \\\n",
    "    --data_path 'tatsu-lab/alpaca' \\\n",
    "    --output_dir '{OUTPUT_DIR}' \\\n",
    "    --batch_size 128 \\\n",
    "    --micro_batch_size 4 \\\n",
    "    --num_epochs {NUM_EPOCHS} \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --learning_rate_policy {LR_POLICY} \\\n",
    "    --option {OPTION} \\\n",
    "    --cutoff_len 512 \\\n",
    "    --val_set_size 2000 \\\n",
    "    --lora_r 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.1\n",
    "\"\"\"\n",
    "\n",
    "subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "tasks = [\"piqa\", \"openbookqa\", \"social_iqa\", \"commonsense_qa\", \"mnli\", \"truthfulqa\", \"hellaswag\", \"ai2_arc\"]\n",
    "task_str = \",\".join(tasks)\n",
    "\n",
    "num_fewshot = 0\n",
    "model_args = \"meta-llama/Llama-2-7b-hf\"\n",
    "checkpoint = \"/path/to/checkpoint\"\n",
    "BASE_DIR = \"/path/to/project\"\n",
    "PEFT_CHECKPOINT = f\"{BASE_DIR}/{checkpoint}\"\n",
    "OUTPUT_DIR = f\"{BASE_DIR}/{checkpoint}_results/output.json\"\n",
    "\n",
    "command = f\"\"\"\n",
    "python -m lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained={model_args},peft={PEFT_CHECKPOINT} \\\n",
    "    --tasks {task_str} \\\n",
    "    --device cuda \\\n",
    "    --batch_size auto:4 \\\n",
    "    --num_fewshot {num_fewshot} \\\n",
    "    --output_path {OUTPUT_DIR} \\\n",
    "    --log_samples\n",
    "\"\"\"\n",
    "\n",
    "subprocess.run(command, shell=True, check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
